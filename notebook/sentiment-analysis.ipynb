{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cümle Analizi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hedefimiz girdi olarak verilen her cümlenin olumlu mu olumsuz mu olduğunu bulmak.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential,load_model\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Veriseti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Halihazırda önişlemeden geçtiği için tüm cümleler 0 veya 1 olarak işaretlenmiş durumda.\n",
    "    * 0 olumsuz \n",
    "    * 1 olumlu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verisetinde 243497 adet cümle mevcut.\n"
     ]
    }
   ],
   "source": [
    "print(\"Verisetinde {} adet cümle mevcut.\".format(len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Örnekleri rahatça görebileceğimiz basit bir fonksiyon yazabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_example(sentence, rate):\n",
    "    tag = \"Olumlu\" if rate else \"Olumsuz\"\n",
    "    print(\"Cümle: {} \\nEtiket: {}\".format(sentence, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Eğitim ve Test Ayırımı"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cümlelerin %80'ini eğitim, geri kalanını test olarak ayıralım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dataset['Rating'].values.tolist()\n",
    "data = dataset['Review'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = int(len(data) * .80)\n",
    "x_train, y_train = data[:ratio], target[:ratio]\n",
    "x_test, y_test   = data[ratio:], target[ratio:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194797 adet cümle eğitim için kullanılacak.\n",
      "48700 adet cümle test için kullanılacak.\n"
     ]
    }
   ],
   "source": [
    "print(\"{} adet cümle eğitim için kullanılacak.\".format(len(x_train)))\n",
    "print(\"{} adet cümle test için kullanılacak.\".format(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Birer olumlu ve olumsuz örnek bakalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cümle: arkdaslar cok arastirma  yaptim  bütün telfonlari arastirdim bu telefonda karar kildim harika bir telefon herseyiy le mükemmel herkese öneriyorum  \n",
      "Etiket: Olumlu\n"
     ]
    }
   ],
   "source": [
    "IDX = 22223\n",
    "see_example(sentence=x_train[IDX], rate=y_train[IDX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cümle: ilk başta iş görür gibi görünüyor ama siz oyuncusunuz günde 300-400 tık yapıyorsunuz 3-4 aya tık ömrü bitiyo sol tıkı kullanamaz hale geliyorsunuz buda aklınızda bulunsun \n",
      "Etiket: Olumsuz\n"
     ]
    }
   ],
   "source": [
    "IDX = 2139\n",
    "see_example(sentence=x_train[IDX], rate=y_train[IDX])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Önişleme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi tokenize işlemine geçip tüm kelimelere birer sayı ataması yapacağız. Ama önce kelime sayısını sınırlandırmakta fayda var. En çok kullanılan 10 bin kelimeyi ele alalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "tokenizer = Tokenizer(num_words=num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 bin kelimelik bir tokenizer oluşturduk şimdi kendi cümlelerimizin tamamını girdi olarak verip kelimelerin **entropi** değerine göre nasıl sıralandığını gözlemleyelim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(data)\n",
    "#tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En çok kullanılan kelimelerin **çok, bir, ve, ürün** olduklarını görebiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi cümleleri kelimeler yerine bu sayılarla oluşturalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokens = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cümlelerimizin yeni ve eski hallerini gözlemleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Öncesi: 1 gün gibi kısa bir sürede elime geçti. Ve bu fıyata süper bir ürün tavsiye ederim. Lakin eli büyük olan kişiler daha büyük modelini tercih edebilirler ortaboy ürün. Teşekkürler \n",
      "Sonrası: [  38   40   20  108    2  161   29  150    3    5 2855   73    2    4\n",
      "    9   10 1159 2430  104  113 2068   11  104 1150  175    4   16]\n"
     ]
    }
   ],
   "source": [
    "IDX = 10\n",
    "print(\"Öncesi: {}\".format(x_train[IDX]))\n",
    "print(\"Sonrası: {}\".format(np.array(x_train_tokens[IDX])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cümlenin iki durumunun boyutlarını incelediğimizde token dizisinin 3 kelime az olduğunu görürüz. Bunun sebebi **girdideki cümlede ilk 10 bin kelime arasına girememiş kelimeler** olmasıdır. Bu kelimeler çok nadir kullanıldığından işlenmesine gerek görülmüyor şimdilik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train[IDX].split(\" \")))\n",
    "print(len(x_train_tokens[IDX]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Girdilerin tamamının aynı boyutta olması bir gerçek. Ancak şu an tüm cümlelerin kendine ait boyutları var."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir sayı seçeceğiz ve verisetinde tüm cümlelerin kelime sayısı hemen hemen bu sayıya yakın veya ona eşit olacak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sentences = x_train_tokens + x_test_tokens\n",
    "num_tokens = np.array([len(tokens) for tokens in total_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.744703220162876"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maksimum bir cümlenin kelime uzunluğu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biraz matematik işlem ile en kullanışlı olacak kelime uzunluğunu buluyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens) # np.std = standart sapma\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cümlelerden kaçı 59 ve altı kelimeye sahipmiş görelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% 95.98\n"
     ]
    }
   ],
   "source": [
    "print(\"%\", round(np.sum(num_tokens < max_tokens) / len(num_tokens) * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PADDING**\n",
    "- Cümlelerin her birinin 59 boyutunda olması gerektiğini bulduk. Peki bu sayıdan az olan veya çok uzunluğa sahip cümleler nasıl etkilenecek?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 59 kelimeden fazla uzunluğu olan cümleler en baştan silinerek 59 kelimeye indirgenecek.\n",
    "* 59 kelimeden az uzunluğu olan cümlelere ise başlarına 0 eklenerek 59'a tamamlanacak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens)\n",
    "x_test_pad  = pad_sequences(x_test_tokens,  maxlen=max_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artık verilerimiz 2 boyutlu bir numpy array olarak saklanıyor. Boyutlarını görelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194797, 59)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48700, 59)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test cümle sayısının 194 bin, test sayısının 48 bin olduğunu da yeniden görmüş olduk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding işleminin sonuçlarını örneklerle inceleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  19  341   52  194   30   54 7992   55  209  603 7887    3   36  114\n",
      "  164  479   85    1 1682  782   30    2  380  326    3    1   81  132\n",
      "  562    9   10] \n",
      "Uzunluk: 31\n",
      "\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "   19  341   52  194   30   54 7992   55  209  603 7887    3   36  114\n",
      "  164  479   85    1 1682  782   30    2  380  326    3    1   81  132\n",
      "  562    9   10] \n",
      "Uzunluk: 59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IDX = 800\n",
    "print(\"{} \\nUzunluk: {}\\n\".format(np.array(x_train_tokens[IDX]), len(x_train_tokens[IDX])))\n",
    "print(\"{} \\nUzunluk: {}\\n\".format(np.array(x_train_pad[IDX]), len(x_train_pad[IDX])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boyutu 31 olan bir cümle başına 0 verileri eklenerek 59'a tamamlanmış.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   5   19  234   85 1223 3811 1410 1820  128   17   56  690 6254 1548\n",
      " 2722 2254   71 3568  405 7548  112  894   71   34 1504  124  414 1738\n",
      "    8  677   83   12    5   19  677 3010   46 1501   36   98   98   12\n",
      "    5   19  146  307 1944 7548 5645    1    6   54   35  124  162  103\n",
      "  791 1419   66   10    5   19   57 3630  113  125   46  176   57 1696] \n",
      "Uzunluk: 70\n",
      "\n",
      "[ 690 6254 1548 2722 2254   71 3568  405 7548  112  894   71   34 1504\n",
      "  124  414 1738    8  677   83   12    5   19  677 3010   46 1501   36\n",
      "   98   98   12    5   19  146  307 1944 7548 5645    1    6   54   35\n",
      "  124  162  103  791 1419   66   10    5   19   57 3630  113  125   46\n",
      "  176   57 1696] \n",
      "Uzunluk: 59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IDX = 253\n",
    "print(\"{} \\nUzunluk: {}\\n\".format(np.array(x_train_tokens[IDX]), len(x_train_tokens[IDX])))\n",
    "print(\"{} \\nUzunluk: {}\\n\".format(np.array(x_train_pad[IDX]), len(x_train_pad[IDX])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boyutu 70 olan bir cümle başından gerekli kadar kelime silinerek 59'a tamamlanmış.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimizde artık kelimeler yok onların token değerleri var. Token değerlerinden kelimelere gidebileceğimiz bir fonksiyon yazalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "INVERSE_MAP = dict(zip(tokenizer.word_index.values(), tokenizer.word_index.keys()))\n",
    "\n",
    "def tokens_to_words(sentence, tokens):\n",
    "    words = [INVERSE_MAP[token] for token in tokens if token!=0]\n",
    "    text = ' '.join(words)\n",
    "    print(\"Öncesi: {} \\n\\nSonrası: {}\".format(sentence, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Öncesi: bloetooth aparatı küçük ve şık. mouse ise çok kullanışlı.  bağlantı sorunu asla yok. aldım ve 1 yıldır kullanıyprum..almak isteyenleree siddetle tavsiya ederim. ucuz ve kaliteli bir ürün. \n",
      "\n",
      "Sonrası: aparatı küçük ve şık mouse ise çok kullanışlı bağlantı sorunu asla yok aldım ve 1 yıldır almak siddetle ederim ucuz ve kaliteli bir ürün\n"
     ]
    }
   ],
   "source": [
    "IDX = 750\n",
    "tokens_to_words(sentence=x_train[IDX], tokens=x_train_tokens[IDX])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- yukarıda ilk olarak verisetinden bir yorum gördük, bazı kelimeler yanlış yazılmış.\n",
    "* ardından ise tokenleştirme işleminden sonra ağımıza vereceğimiz cümlenin yeni halini gördük.\n",
    "- yeni cümlede yanlış yazılan kelimeler veya az kullanılan kelimeler silinmiş."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- RNN Oluşturma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Önişleme süreci bittikten sonra artık sinir ağını oluşturabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/md/.local/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/md/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/md/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/md/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/md/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/md/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Found a model!\n"
     ]
    }
   ],
   "source": [
    "have_a_model = True\n",
    "MODEL_PATH = \"../models/my_model.h5\"\n",
    "\n",
    "if have_a_model:\n",
    "    model = load_model(MODEL_PATH)\n",
    "    print(\"Found a model!\")\n",
    "\n",
    "else:\n",
    "    print(\"Found no model. Creating one.\")\n",
    "    model = Sequential()\n",
    "\n",
    "    embedding_size = 50\n",
    "\n",
    "    model.add(Embedding(input_dim=num_words,\n",
    "                        output_dim=embedding_size,\n",
    "                        input_length=max_tokens,\n",
    "                        name='embedding_layer'))\n",
    "\n",
    "    model.add(GRU(units=16, return_sequences=True))\n",
    "    model.add(GRU(units=8, return_sequences=True))\n",
    "    model.add(GRU(units=4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    optimizer = Adam(lr=1e-3)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train_pad, y_train, epochs=5, batch_size=256)\n",
    "    model.save(MODEL_PATH)\n",
    "    clear_output()\n",
    "    print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin özetini görelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, 59, 50)            500000    \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 59, 16)            3216      \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 59, 8)             600       \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 4)                 156       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 503,977\n",
      "Trainable params: 503,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model eğitildi. Şimdi test için ayırdığımız veriyi modele verip çıktıyı görelim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Analiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48700/48700 [==============================] - 36s 732us/sample - loss: 0.1576 - acc: 0.9530\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin %95 oranında başarılı olduğunu gördük."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15759055556733262, 0.9529979]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test verisindeki 48700 adet cümleden 46410 tanesi doğru bilindi.\n"
     ]
    }
   ],
   "source": [
    "num_true_sentence = int(len(x_test) * result[1])\n",
    "print(\"Test verisindeki {} adet cümleden {} tanesi doğru bilindi.\".format(len(x_test), num_true_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate** fonksiyonu yalnızca accuracy ve loss değerini döndürür. Tek tek cümlelerin sonuçlarını görmek için **predict**'i kullanabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48700, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her cümle için çıktı 0 ile 1 arasındadır. 0 bildiğimiz gibi olumsuz 1 olumlu anlamındadır. 0.5 üzerini olumlu altını olumsuz olarak işaretleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.array([1 if p>0.5 else 0 for p in y_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cümleyi\n",
    "- Cümlenin Asıl Etiketini\n",
    "* Cümlenin Üretilmiş Etikeni\n",
    "\n",
    "bir arada görelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cümle: işyerindeki yavru kedilerimiz için aldım, bayılıyorlar yerken. Başka bir mamaya alışmamış yavrular için bence uygun bir seçenek. Fiyatı da diğerlerinden uygun. \n",
      "Asıl Etiket: 1 \n",
      "Üretilen Etiket: 1\n"
     ]
    }
   ],
   "source": [
    "IDX = 1000\n",
    "sentence = x_test[IDX]\n",
    "real_rate = y_test[IDX]\n",
    "predicted_rate = test_pred[IDX]\n",
    "\n",
    "print(\"Cümle: {} \\nAsıl Etiket: {} \\nÜretilen Etiket: {}\".format(sentence, real_rate, predicted_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6- Testler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi kendi yazdığımız birkaç cümle ve sonuçlarına göz atalım."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test cümlelerini tanımlayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\"iyi paketleme ama beğenmedim.\",\n",
    "            \"Çok kötü.\",\n",
    "            \"Kötü kargo ürün kötü değil ama kullanım tarihi geçmiş.\"\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenleştirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.texts_to_sequences(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding işlemini gerçekleştirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_pad = pad_sequences(tokens, maxlen=59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test token'larını modele verelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(tokens_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sonuçlardan 0.5 üzerini olumlu, diğerlerini olumsuz yapıp çıktıyı anlamlaştıralım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = np.array([1 if result>0.5 else 0 for result in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cümle: iyi paketleme ama beğenmedim. \n",
      "Etiket: Olumsuz\n",
      "Cümle: Çok kötü. \n",
      "Etiket: Olumsuz\n",
      "Cümle: Kötü kargo ürün kötü değil ama kullanım tarihi geçmiş. \n",
      "Etiket: Olumlu\n"
     ]
    }
   ],
   "source": [
    "for s,r in zip(sentence, new_pred):\n",
    "    see_example(s,r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
